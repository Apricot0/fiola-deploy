import os
import numpy as np
import scipy.io as sio
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import joblib  # used for saving/loading the scaler

# ======================================================
# 1. Utility Functions
# ======================================================

def get_max_neurons(file_list):
    """
    Loop through a list of .mat files and return the maximum number
    of spike channels found. This is used to pad spike data to a fixed width.
    """
    max_neurons = 0
    for file in file_list:
        data = sio.loadmat(file)
        spks = data['spks']  # shape: (n_neurons, n_frames)
        n_neurons = spks.shape[0]
        if n_neurons > max_neurons:
            max_neurons = n_neurons
    return max_neurons

#CHECKED
def load_mat_file(filepath, max_neurons = None):
    """
    Load a MAT file generated by CaImAn and return a merged feature matrix.
    
    Assumes the MAT file contains:
      - t         : (n_frames, 1)   Time stamps
      - arena_x   : (n_frames, 1)
      - arena_y   : (n_frames, 1)
      - spks      : (n_neurons, n_frames)  Spike traces
    
    This function transposes spks so that each row corresponds to one frame,
    resulting in an array of shape: (n_frames, max_neurons)
    """
    data = sio.loadmat(filepath)
    t = data['t']              # shape: (n_frames, 1)
#     arena_x = data['arena_x']  # shape: (n_frames, 1)
#     arena_y = data['arena_y']  # shape: (n_frames, 1)
    spks = data['spks']        # shape: (n_neurons, n_frames)
    
    # Transpose spks so that rows correspond to frames
    spks = spks.T             # new shape: (n_frames, n_neurons)
    n_frames, n_neurons = spks.shape
    
    # Pad spike data with zeros to reach max_neurons columns if needed.
    if max_neurons and n_neurons < max_neurons:
        padding = np.zeros((n_frames, max_neurons - n_neurons))
        spks = np.concatenate([spks, padding], axis=1)
    
    return spks

#CHECKED
def create_sequences(data, window_size=50, step=1):
    """
    Given a 2D array (n_frames, n_features), slice it into overlapping
    sequences of length `window_size`. The `step` parameter controls the sliding.
    
    Returns:
      sequences: array of shape (n_sequences, window_size, n_features)
    """
    sequences = []
    for i in range(0, data.shape[0] - window_size + 1, step):
        seq = data[i:i+window_size, :]
        sequences.append(seq)
    return np.array(sequences)

def classify_frame_sequence(model, frame_buffer, scaler, window_size=50):
    """
    Given a list (buffer) of frames (each a 1D array of features),
    use the trained model to classify whether the current condition is
    'light' (True) or 'dark' (False). The buffer must contain at least
    `window_size` frames.
    
    Returns:
      - True if predicted as light (activation > 0.5)
      - False if dark
      - None if there are insufficient frames
    """
    if len(frame_buffer) < window_size:
        return None  # Not enough frames yet.
    
    # Use the most recent window_size frames
    sequence = np.array(frame_buffer[-window_size:])
    # Scale using the saved scaler (assumes scaler was fitted on training data)
    sequence_scaled = scaler.transform(sequence)
    sequence_scaled = sequence_scaled.reshape(1, window_size, -1)
    
    pred = model.predict(sequence_scaled)
    return (pred[0, 0] > 0.5)

# ======================================================
# 2. Training Pipeline (Using 6 Files)
# ======================================================

if __name__ == '__main__':
    # 2.1 Define File Names and Labels for Training
    light_files = ['light_1.mat', 'light_2.mat']
    dark_files  = ['dark_1.mat', 'dark_2.mat']
    
    # Label convention: light = 1, dark = 0.
    labels_dict = {}
    for f in light_files:
        labels_dict[f] = 1
    for f in dark_files:
        labels_dict[f] = 0
    all_files = light_files + dark_files
    
    # 2.2 Determine the maximum number of neurons (for padding)
    max_neurons = get_max_neurons(all_files)
    print("Maximum number of neurons found across sessions:", max_neurons)
    
    # 2.3 Create Sequences for Each File (using a sliding window)
    window_size = 50  # number of frames per sequence
    X_list = []  # will hold sequences from all sessions
    y_list = []  # corresponding labels
    for file in all_files:
        print("Processing file:", file)
        features = load_mat_file(file, max_neurons)
        sequences = create_sequences(features, window_size=window_size, step=1)
        X_list.append(sequences)
        file_label = labels_dict[file]
        y_list.append(np.full((sequences.shape[0],), file_label))
    
    # Concatenate sequences and labels from all files.
    X = np.concatenate(X_list, axis=0)
    y = np.concatenate(y_list, axis=0)
    print("Total sequences shape:", X.shape, "; Total labels shape:", y.shape)
    
    # 2.4 Split Data into Train/Validation/Test (stratified so that both conditions appear in each set)
    X_temp, X_test, y_temp, y_test = train_test_split(
        X, y, test_size=0.85, random_state=42, stratify=y
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=0.15/0.85, random_state=42, stratify=y_temp
    )

    # print("hello")

    # split_ratios = [0.7, 0.15, 0.15]  # Train: 70%, Validation: 15%, Test: 15%
    # split_names = ["train", "val", "test"]

    # indices = np.arange(len(X))
    # # np.random.shuffle(indices)

    # splits = {}
    # start = 0

    # for i, split_ratio in enumerate(split_ratios):
    #     end = start + int(split_ratio * len(X))  # Calculate end index
    #     splits[split_names[i]] = indices[start:end]  # Store indices for this split
    #     start = end  # Update start for next split

    # X_train, X_val, X_test = X[splits["train"]], X[splits["val"]], X[splits["test"]]
    # y_train, y_val, y_test = y[splits["train"]], y[splits["val"]], y[splits["test"]]

    # Print shapes
    print(f"Train set: {X_train.shape}, {y_train.shape}")
    print(f"Validation set: {X_val.shape}, {y_val.shape}")
    print(f"Test set: {X_test.shape}, {y_test.shape}")

    print("Training set shape:", X_train.shape)
    print("Validation set shape:", X_val.shape)
    print("Test set shape:", X_test.shape)
    
    # 2.5 Standardize Features
    # Reshape training data to 2D, fit the scaler, and reshape back.
    n_train, seq_len, n_features = X_train.shape
    X_train_reshaped = X_train.reshape(-1, n_features)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train_reshaped)
    X_train = X_train_scaled.reshape(n_train, seq_len, n_features)
    
    # Apply the same transformation to validation and test data.
    n_val = X_val.shape[0]
    X_val = scaler.transform(X_val.reshape(-1, n_features)).reshape(n_val, seq_len, n_features)
    n_test = X_test.shape[0]
    X_test = scaler.transform(X_test.reshape(-1, n_features)).reshape(n_test, seq_len, n_features)
    
    # 2.6 Build and Train the LSTM Model
    model = Sequential()
    # (Using an Input layer explicitly is recommended, but here we follow the previous approach)
    model.add(LSTM(64, input_shape=(window_size, n_features), return_sequences=True))
    model.add(Dropout(0.2))
    model.add(LSTM(32))
    model.add(Dropout(0.2))
    model.add(Dense(1, activation='sigmoid'))  # Binary classification (light/dark)
    
    model.compile(optimizer=Adam(learning_rate=0.001),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    
    model.summary()
    
    history = model.fit(
        X_train, y_train,
        epochs=10,
        batch_size=64,
        validation_data=(X_val, y_val)
    )
    
    test_loss, test_acc = model.evaluate(X_test, y_test)
    print("Test Accuracy: {:.2f}%".format(test_acc * 100))
    
    # 2.7 Save the Model and the Scaler for Real-Life Testing
    model_path = 'lstm_model.h5'
    scaler_path = 'scaler.save'
    model.save(model_path)
    joblib.dump(scaler, scaler_path)
    print("Model and scaler saved.")

    # ======================================================
    # 3. Real-Life Testing Simulation (Using 1 Light and 1 Dark MAT File)
    # ======================================================
    # In a real-life application you might get new MAT files on the fly.
    # For simulation, we use one light file and one dark file.
    test_light_file = 'light_3.mat'
    test_dark_file  = 'dark_3.mat'
    
    # (Optionally, recompute or use the same max_neurons from training)
    print("\nReal-life Testing Simulation:")
    features_light = load_mat_file(test_light_file, max_neurons)
    features_dark = load_mat_file(test_dark_file, max_neurons)
    
    # Create sequences from each file using the same window_size.
    sequences_light = create_sequences(features_light, window_size=window_size, step=1)
    sequences_dark  = create_sequences(features_dark, window_size=window_size, step=1)
    
    labels_light = np.ones(sequences_light.shape[0])  # Light = 1
    labels_dark  = np.zeros(sequences_dark.shape[0])   # Dark  = 0
    
    # Combine the sequences and labels from the two files.
    X_realtime = np.concatenate([sequences_light, sequences_dark], axis=0)
    y_realtime = np.concatenate([labels_light, labels_dark], axis=0)
    
    # Shuffle the combined set.
    indices = np.arange(X_realtime.shape[0])
    np.random.shuffle(indices)
    X_realtime = X_realtime[indices]
    y_realtime = y_realtime[indices]
    
    # Load the saved model and scaler.
    loaded_model = load_model(model_path)
    loaded_scaler = joblib.load(scaler_path)
    
    # Rescale the real-time data.
    n_rt_samples = X_realtime.shape[0]
    X_realtime = loaded_scaler.transform(X_realtime.reshape(-1, n_features)).reshape(n_rt_samples, window_size, n_features)
    
    # Get predictions for the combined set.
    predictions = loaded_model.predict(X_realtime)
    predicted_labels = (predictions[:, 0] > 0.5).astype(int)
    
    # Compute and print simulated "real-time" accuracy.
    accuracy_rt = np.mean(predicted_labels == y_realtime)
    print("Real-time simulated accuracy on combined light_1 and dark_1: {:.2f}%".format(accuracy_rt * 100))
    
    # Optionally, show a few sample predictions.
    for i in range(10):
        true_str = "Light" if y_realtime[i] == 1 else "Dark"
        pred_str = "Light" if predicted_labels[i] == 1 else "Dark"
        print(f"Sequence {i}: True Label: {true_str} | Predicted: {pred_str}")
    
    # Example of using the real-time inference function on a simulated frame buffer:
    # (Assume we are receiving frames one by one)
    # Here we simulate by taking the first sequence from the real-time set.
    example_sequence = X_realtime[0]  # shape: (window_size, n_features)
    frame_buffer = [frame for frame in example_sequence]  # simulate a buffer of frames
    realtime_pred = classify_frame_sequence(loaded_model, frame_buffer, loaded_scaler, window_size=window_size)
    print("Real-time classification prediction (from buffer simulation):", 
          "Light" if realtime_pred else "Dark")
